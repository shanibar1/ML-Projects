{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv(\"XY_train.csv\", encoding='iso-8859-1')\n",
    "\n",
    "# ======== MISSION 0 ========\n",
    "# split input dataset to training dataset & testing dataset\n",
    "\n",
    "# remove irrelevant columns\n",
    "df_imputed = df.drop(columns=['ID', 'POSTAL_CODE'])\n",
    "\n",
    "# convert values to numerical\n",
    "df_imputed['GENDER'] = df_imputed['GENDER'].map({'male': 0, 'female': 1})\n",
    "df_imputed['EDUCATION'] = df_imputed['EDUCATION'].map({'none': 0, 'high school': 1, 'university': 2})\n",
    "df_imputed['VEHICLE_TYPE'] = df_imputed['VEHICLE_TYPE'].map({'sedan': 0, 'sports car': 1})\n",
    "df_imputed['VEHICLE_YEAR'] = df_imputed['VEHICLE_YEAR'].map({'before 2015': 0, 'after 2015': 1})\n",
    "df_imputed['INCOME'] = df_imputed['INCOME'].map({'poverty': 0, 'working class': 1, 'middle class': 2, 'upper class': 3})\n",
    "\n",
    "df_imputed['AGE'] = pd.cut(df_imputed['AGE'], bins=[0, 20, 30, 50, 70, 100], labels=[0, 1, 2, 3, 4])\n",
    "df_imputed['DRIVING_EXPERIENCE'] = pd.cut(df_imputed['DRIVING_EXPERIENCE'], bins=[0, 1, 3, 10, 20, 100],\n",
    "                                          labels=[0, 1, 2, 3, 4])\n",
    "\n",
    "# remove rows with missing values\n",
    "df_imputed = df_imputed.dropna()\n",
    "\n",
    "# save the imputed dataset\n",
    "df_imputed.to_csv('XY_train_imputed.csv', index=False)\n",
    "\n",
    "# define X (features) and Y (target variable for prediction)\n",
    "# target variable is 'OUTCOME'\n",
    "\n",
    "X = df_imputed.drop(columns=['OUTCOME'])\n",
    "Y = df_imputed['OUTCOME']\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "\n",
    "# ======== MISSION 1 ========\n",
    "\n",
    "# define a new DecisionTreeClassifier\n",
    "dtc = DecisionTreeClassifier()\n",
    "dtc.fit(X_train, Y_train)\n",
    "\n",
    "\n",
    "def print_dtc_score(dtc, X_train, Y_train, X_test, Y_test):\n",
    "    # determining the prediction accuracy can be done with\n",
    "    # DecisionTreeClassifier.score or\n",
    "    # sklearn.metrics.roc_auc_score\n",
    "\n",
    "    print(\"=================== MODEL ACCURACY SCORES ===================\")\n",
    "\n",
    "    # ===== accuracy score =====\n",
    "    y_train_pred = dtc.predict(X_train)\n",
    "\n",
    "    # calculate accuracy\n",
    "    score = accuracy_score(Y_train, y_train_pred)\n",
    "    # print the accuracy of the model for the training dataset\n",
    "    print(f\"Model accuracy score for TRAINING dataset: {score}\")\n",
    "    y_test_pred = dtc.predict(X_test)\n",
    "    # print the accuracy of the model for the test dataset\n",
    "    score = accuracy_score(Y_test, y_test_pred)\n",
    "    print(f\"Model accuracy score for TEST dataset: {score}\")\n",
    "\n",
    "\n",
    "print_dtc_score(dtc, X_train, Y_train, X_test, Y_test)\n",
    "\n",
    "# ======== MISSION 3 ========\n",
    "# we need to do hyperparameter tuning to improve the model's performance\n",
    "# we can use GridSearchCV to find the best hyperparameters\n",
    "\n",
    "# plotting the leaves amount with help of kfold to check accuracy using AUC-ROC\n",
    "Min_Sample_Leaves_Amount = np.arange(1, 1350, 50)\n",
    "TreeModel = DecisionTreeClassifier(random_state=42)\n",
    "SKFold_CV = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n",
    "ParamatersDict = {'min_samples_leaf': Min_Sample_Leaves_Amount}\n",
    "\n",
    "# using grid search to find min leaves amount that we can starting our paraments from:\n",
    "grid = GridSearchCV(estimator=TreeModel, param_grid=ParamatersDict, scoring='accuracy',\n",
    "                    cv=SKFold_CV, n_jobs=-1, refit=True, return_train_score=True)\n",
    "grid.fit(X_train, Y_train)\n",
    "cv_results = pd.DataFrame(grid.cv_results_)\n",
    "Selected_Leaves = ['mean_test_score',\n",
    "                   'mean_train_score', 'param_min_samples_leaf']\n",
    "\n",
    "DF_Selected_Values = cv_results[Selected_Leaves]\n",
    "DF_Selected_Values = DF_Selected_Values.sort_values(\n",
    "    'param_min_samples_leaf', ascending=True)\n",
    "\n",
    "plt.figure(figsize=(13, 4))\n",
    "plt.plot(DF_Selected_Values['param_min_samples_leaf'],\n",
    "         DF_Selected_Values['mean_train_score'], marker='x', markersize=4)\n",
    "plt.plot(DF_Selected_Values['param_min_samples_leaf'],\n",
    "         DF_Selected_Values['mean_test_score'], marker='o', markersize=4)\n",
    "plt.title('min samples leaves accuracy score')\n",
    "plt.legend(['Train accuracy', 'Validation accuracy'])\n",
    "plt.xlabel('min_samples_leaf')\n",
    "plt.xticks([int(x) for x in DF_Selected_Values['param_min_samples_leaf']])\n",
    "plt.ylabel('accuracy score')\n",
    "#plt.show()\n",
    "\n",
    "# define the hyperparameters to tune\n",
    "max_depth_list = np.arange(1, 20)\n",
    "leaf_samples = np.arange(50, 300, 5)\n",
    "params_dt = {\n",
    "    'max_depth': max_depth_list,\n",
    "    'criterion': ['entropy', 'gini'],\n",
    "    'class_weight': ['balanced', None],\n",
    "    'min_samples_leaf': leaf_samples,\n",
    "}\n",
    "# define the GridSearchCV\n",
    "TreeModel = DecisionTreeClassifier(random_state=42)\n",
    "SKFold_CV = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n",
    "# use grid tree to tune the parameters\n",
    "Grids_Tree = GridSearchCV(estimator=TreeModel, param_grid=params_dt, scoring='accuracy',\n",
    "                          cv=SKFold_CV, n_jobs=-1, refit=True, return_train_score=True)\n",
    "Grids_Tree.fit(X_train, Y_train)\n",
    "\n",
    "best_hyperparameters = Grids_Tree.best_params_\n",
    "best_TreeModel = Grids_Tree.best_estimator_\n",
    "\n",
    "# plot the best hyperparameters using matplotlib\n",
    "\n",
    "cv_results = pd.DataFrame(Grids_Tree.cv_results_)\n",
    "Selected_Leaves = ['std_test_score', 'mean_test_score', 'mean_train_score',\n",
    "                   'param_max_depth', 'param_criterion', 'param_class_weight', 'param_min_samples_leaf']\n",
    "DF_Selected_Values = cv_results[Selected_Leaves]\n",
    "DF_Selected_Values = DF_Selected_Values.sort_values(\n",
    "    'mean_test_score', ascending=False).head(10)\n",
    "DF_Selected_Values['mean_test_score'] = DF_Selected_Values['mean_test_score'].round(\n",
    "    4)\n",
    "DF_Selected_Values['mean_train_score'] = DF_Selected_Values['mean_train_score'].round(\n",
    "    4)\n",
    "DF_Selected_Values['std_test_score'] = DF_Selected_Values['std_test_score'].round(\n",
    "    4)\n",
    "column_names = {\n",
    "    'mean_test_score': 'Mean test score',\n",
    "    'mean_train_score': 'Mean train score',\n",
    "    'param_max_depth': 'Max depth',\n",
    "    'param_criterion': 'Criterion',\n",
    "    'param_class_weight': 'Class weight',\n",
    "    'param_min_samples_leaf': 'Min samples leaf',\n",
    "    'std_test_score': 'std test score'\n",
    "}\n",
    "\n",
    "# plot the results\n",
    "DF_Selected_Values = DF_Selected_Values.rename(columns=column_names)\n",
    "fig, ax = plt.subplots(figsize=(10, 3))\n",
    "ax.axis('off')\n",
    "ax.set_title('Grid Search results', y=1.1)\n",
    "table = ax.table(cellText=DF_Selected_Values.values,\n",
    "                 colLabels=DF_Selected_Values.columns, loc='center')\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(12)\n",
    "table.scale(1.25, 1.25)\n",
    "#plt.show()\n",
    "\n",
    "# features importance:\n",
    "\n",
    "importance = pd.DataFrame({'Feature_name': X_train.columns,\n",
    "                           'Importance': best_TreeModel.feature_importances_.round(4)})\n",
    "\n",
    "# sort the DataFrame by importance in descending order\n",
    "importance = importance.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9, 10))\n",
    "ax.axis('off')\n",
    "table = ax.table(cellText=importance.values,\n",
    "                 colLabels=importance.columns, loc='center')\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(11)\n",
    "table.scale(0.6, 1.5)\n",
    "#plt.show()\n",
    "\n",
    "# ======== MISSION 4 ========\n",
    "best_estimator = Grids_Tree.best_estimator_\n",
    "best_params = Grids_Tree.best_params_\n",
    "\n",
    "# print the accuracy scores for the best estimator model\n",
    "print_dtc_score(best_estimator, X_train, Y_train, X_test, Y_test)\n",
    "\n",
    "# plot the tree for the best estimator model\n",
    "plt.figure(figsize=(20, 16))\n",
    "plot_tree(best_estimator, filled=True, max_depth=2, feature_names=X_train.columns, class_names=['0', '1'], fontsize=6)\n",
    "plt.savefig('decision_tree.png')\n",
    "\n",
    "# print the feature importance for the best estimator model (ordered by importance)\n",
    "feature_importances = best_estimator.feature_importances_\n",
    "feature_importances = [(feature_name, importance) for feature_name, importance in\n",
    "                       zip(X_train.columns, feature_importances)]\n",
    "feature_importances = sorted(feature_importances, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"=================== FEATURE IMPORTANCE SCORES ===================\")\n",
    "for feature_name, importance in feature_importances:\n",
    "    print(f\"{feature_name}: {importance}\")\n"
   ],
   "id": "a715b8710a85a924",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "best_params = Grids_Tree.best_params_\n",
    "print(\"Best hyperparameters:\", best_params)\n"
   ],
   "id": "1057255559b9a967",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pickle\n",
    "\n",
    "# Save the best model to a file\n",
    "with open('best_decision_tree_model.pkl', 'wb') as file:\n",
    "    pickle.dump(best_estimator, file)\n",
    "\n",
    "print(\"Best model saved as 'best_decision_tree_model.pkl'\")\n"
   ],
   "id": "655fd85061bd166c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import multivariate_normal\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, make_scorer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "from sympy.physics.control.control_plots import matplotlib\n",
    "\n",
    "# Load data\n",
    "from google.colab import files\n",
    "uploaded = files.upload()\n",
    "XY_train = pd.read_csv(\"XY_train.csv\")\n",
    "\n",
    "#missing data\n",
    "missing_data_per_column = XY_train.isnull().sum()\n",
    "print(missing_data_per_column)\n",
    "#filling data using KNN\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# Calculate the correlation between ANNUAL_MILEAGE and OUTCOME\n",
    "correlation1 = XY_train['ANNUAL_MILEAGE'].corr(XY_train['OUTCOME'])\n",
    "correlation2 = XY_train['CREDIT_SCORE'].corr(XY_train['OUTCOME'])\n",
    "\n",
    "numeric_columns = [\"ANNUAL_MILEAGE\", \"CREDIT_SCORE\"]\n",
    "knn_imputer = KNNImputer(n_neighbors=6)\n",
    "\n",
    "#Apply KNN Imputer only to the numeric columns\n",
    "df_numeric = pd.DataFrame(\n",
    "    knn_imputer.fit_transform(XY_train[numeric_columns]),\n",
    "    columns=numeric_columns\n",
    ")\n",
    "\n",
    "#Replace the original columns with the imputed ones\n",
    "XY_train[numeric_columns] = df_numeric\n",
    "\n",
    "# Inspect the column names and order\n",
    "print(\"Column Names after Dropping ID:\")\n",
    "print(XY_train.columns)\n",
    "\n",
    "# Encode categorical columns by name\n",
    "# GENDER\n",
    "XY_train['GENDER'] = XY_train['GENDER'].str.strip().map({\"male\": 0, \"female\": 1})\n",
    "\n",
    "# EDUCATION\n",
    "education_map = {\"none\": 0, \"high school\": 1, \"university\": 2}\n",
    "XY_train['EDUCATION'] = XY_train['EDUCATION'].str.strip().map(education_map)\n",
    "\n",
    "# INCOME\n",
    "income_map = {\"poverty\": 0, \"working class\": 1, \"middle class\": 2, \"upper class\": 3}\n",
    "XY_train['INCOME'] = XY_train['INCOME'].str.strip().map(income_map)\n",
    "\n",
    "# VEHICLE_YEAR\n",
    "vehicle_year_map = {\"before 2015\": 0, \"after 2015\": 1}\n",
    "XY_train['VEHICLE_YEAR'] = XY_train['VEHICLE_YEAR'].str.strip().map(vehicle_year_map)\n",
    "\n",
    "# VEHICLE_TYPE\n",
    "vehicle_type_map = {\"sedan\": 0, \"sports car\": 1}\n",
    "XY_train['VEHICLE_TYPE'] = XY_train['VEHICLE_TYPE'].str.strip().map(vehicle_type_map)\n",
    "\n",
    "# Verify the updated dataset\n",
    "print(\"\\nUpdated DataFrame Head:\")\n",
    "print(XY_train.head())\n",
    "\n",
    "#now with standarization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Separate features and labels\n",
    "X = XY_train.drop(columns=['ID','OUTCOME'])\n",
    "Y = XY_train['OUTCOME']\n",
    "\n",
    "# Normalize the features using StandardScaler\n",
    "scaler = MinMaxScaler()\n",
    "normalized_features = scaler.fit_transform(X)\n",
    "\n",
    "# Set a random seed for reproducibility\n",
    "random_seed = 42\n",
    "XY_train.keys()\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "pd.value_counts(Y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=123)\n",
    "print(f\"Train size: {X_train.shape[0]}\")\n",
    "print(f\"Test size: {X_test.shape[0]}\")\n",
    "print(\"Train\\n-----------\\n\", pd.value_counts(Y_train)/Y_train.shape[0])\n",
    "print(\"\\nTest\\n-----------\\n\", pd.value_counts(Y_test)/Y_test.shape[0])\n",
    "#Default model\n",
    "model = MLPClassifier(random_state=42)\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# תחזיות המודל על סט האימון והבחינה\n",
    "train_predictions = model.predict(X_train)  # X_train הוא מערך התכונות בסט האימון\n",
    "test_predictions = model.predict(X_test)    # X_test הוא מערך התכונות בסט הבחינה\n",
    "\n",
    "# חישוב ה-accuracy\n",
    "train_accuracy = accuracy_score(Y_train, train_predictions)  # y_train הוא ה-labels בסט האימון\n",
    "test_accuracy = accuracy_score(Y_test, test_predictions)      # y_test הוא ה-labels בסט הבחינה\n",
    "\n",
    "# הדפסת התוצאות\n",
    "print(f\"Train Accuracy: {train_accuracy * 100:.2f}%\")\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "**סעיף2- grid search**\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(50,), (50, 25), (75, 50, 25)],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'alpha': [0.0001, 0.001, 0.01, 0.1],\n",
    "    'learning_rate': ['adaptive', 'invscaling'],\n",
    "    'learning_rate_init': [0.0001, 0.001, 0.01],\n",
    "    'max_iter': [200, 400],\n",
    "    'solver': ['adam', 'sgd'],\n",
    "    'early_stopping': [True, False]\n",
    "}\n",
    "\n",
    "# Set up GridSearchCV with a refined grid\n",
    "grid_search = GridSearchCV(estimator=mlp, param_grid=param_grid, scoring=make_scorer(f1_score, pos_label=1), cv=5, verbose=3, n_jobs=-1)\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "grid_search.fit(X_train,Y_train)\n",
    "#improved model\n",
    "improvedModel = grid_search.best_estimator_\n",
    "improvedModel.fit(X_train, Y_train)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# תחזיות המודל על סט האימון והבחינה\n",
    "train_predictions = improvedModel.predict(X_train)  # X_train הוא מערך התכונות בסט האימון\n",
    "test_predictions = improvedModel.predict(X_test)    # X_test הוא מערך התכונות בסט הבחינה\n",
    "\n",
    "# חישוב ה-accuracy\n",
    "train_accuracy = accuracy_score(Y_train, train_predictions)  # y_train הוא ה-labels בסט האימון\n",
    "test_accuracy = accuracy_score(Y_test, test_predictions)      # y_test הוא ה-labels בסט הבחינה\n",
    "\n",
    "# הדפסת התוצאות\n",
    "print(f\"Train Accuracy: {train_accuracy * 100:.2f}%\")\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "\n",
    "####Heat map\n",
    "#HEAT-MAP פרמטרים\n",
    "# יצירת Heat Map 1\n",
    "# Convert the grid search results to a DataFrame\n",
    "results = pd.DataFrame(grid_search.cv_results_)\n",
    "\n",
    "# Heat Map 1: Hidden Layer Sizes and Activation\n",
    "heatmap_data = results.pivot_table(index='param_hidden_layer_sizes', columns='param_activation', values='mean_test_score', aggfunc='mean')\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(heatmap_data, annot=True, cmap='YlGnBu', fmt='.3f', cbar=True)\n",
    "plt.title('Heat Map of Grid Search Results for hidden layer sizes and activation', fontsize=20)\n",
    "plt.xlabel('Activation', fontsize=14)\n",
    "plt.ylabel('Hidden Layer Sizes', fontsize=14)\n",
    "plt.show()\n",
    "\n",
    "# Heat Map 2: Alpha and Learning Rate\n",
    "heatmap_data = results.pivot_table(index='param_alpha', columns='param_learning_rate', values='mean_test_score', aggfunc='mean')\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(heatmap_data, annot=True, cmap='YlGnBu', fmt='.3f', cbar=True)\n",
    "plt.title('Heat Map of Grid Search Results for alpha and learning rate', fontsize=20)\n",
    "plt.xlabel('Learning Rate', fontsize=14)\n",
    "plt.ylabel('Alpha', fontsize=14)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Heat Map 3: learning_rate_init and max_iter\n",
    "heatmap_data = results.pivot_table(index='param_learning_rate_init', columns='param_max_iter', values='mean_test_score', aggfunc='mean')\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(heatmap_data, annot=True, cmap='YlGnBu', fmt='.3f', cbar=True)\n",
    "plt.title('Heat Map of Grid Search Results for hidden layer sizes and activation', fontsize=20)\n",
    "plt.xlabel('max_iter', fontsize=14)\n",
    "plt.ylabel('learning_rate_init', fontsize=14)\n",
    "plt.show()\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# תחזית על סט הבדיקות\n",
    "Y_pred = improvedModel.predict(X_test)\n",
    "\n",
    "# חישוב מטריצת המבוכה\n",
    "cm = confusion_matrix(Y_test, Y_pred)\n",
    "\n",
    "# הצגת מטריצת המבוכה\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n"
   ],
   "id": "6f5c6377cd5aba04",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from sympy.physics.control.control_plots import matplotlib\n",
    "\n",
    "# Load data\n",
    "XY_train = pd.read_csv(\"XY_train.csv\")\n",
    "\n",
    "#missing data\n",
    "missing_data_per_column = XY_train.isnull().sum()\n",
    "print(missing_data_per_column)"
   ],
   "id": "758b80eaab84a193",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#filling data using KNN\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# Calculate the correlation between ANNUAL_MILEAGE and OUTCOME\n",
    "correlation1 = XY_train['ANNUAL_MILEAGE'].corr(XY_train['OUTCOME'])\n",
    "correlation2 = XY_train['CREDIT_SCORE'].corr(XY_train['OUTCOME'])\n",
    "\n",
    "numeric_columns = [\"ANNUAL_MILEAGE\", \"CREDIT_SCORE\"]\n",
    "knn_imputer = KNNImputer(n_neighbors=6)\n",
    "\n",
    "#Apply KNN Imputer only to the numeric columns\n",
    "df_numeric = pd.DataFrame(\n",
    "    knn_imputer.fit_transform(XY_train[numeric_columns]),\n",
    "    columns=numeric_columns\n",
    ")\n",
    "\n",
    "#Replace the original columns with the imputed ones\n",
    "XY_train[numeric_columns] = df_numeric\n"
   ],
   "id": "ba5db755d752509b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Print data types of all columns\n",
    "print(\"Data Types:\")\n",
    "print(XY_train.dtypes)"
   ],
   "id": "46010417e2587abc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Drop the first column (ID)\n",
    "\n",
    "\n",
    "# Inspect the column names and order\n",
    "print(\"Column Names after Dropping ID:\")\n",
    "print(XY_train.columns)\n",
    "\n",
    "# Encode categorical columns by name\n",
    "# GENDER\n",
    "XY_train['GENDER'] = XY_train['GENDER'].str.strip().map({\"male\": 0, \"female\": 1})\n",
    "\n",
    "# EDUCATION\n",
    "education_map = {\"none\": 0, \"high school\": 1, \"university\": 2}\n",
    "XY_train['EDUCATION'] = XY_train['EDUCATION'].str.strip().map(education_map)\n",
    "\n",
    "# INCOME\n",
    "income_map = {\"poverty\": 0, \"working class\": 1, \"middle class\": 2, \"upper class\": 3}\n",
    "XY_train['INCOME'] = XY_train['INCOME'].str.strip().map(income_map)\n",
    "\n",
    "# VEHICLE_YEAR\n",
    "vehicle_year_map = {\"before 2015\": 0, \"after 2015\": 1}\n",
    "XY_train['VEHICLE_YEAR'] = XY_train['VEHICLE_YEAR'].str.strip().map(vehicle_year_map)\n",
    "\n",
    "# VEHICLE_TYPE\n",
    "vehicle_type_map = {\"sedan\": 0, \"sports car\": 1}\n",
    "XY_train['VEHICLE_TYPE'] = XY_train['VEHICLE_TYPE'].str.strip().map(vehicle_type_map)\n",
    "\n",
    "# Verify the updated dataset\n",
    "print(\"\\nUpdated DataFrame Head:\")\n",
    "print(XY_train.head())\n"
   ],
   "id": "d2c81041f4e27b8e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import  seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "sns.pairplot(XY_train, hue='OUTCOME')\n",
    "plt.show()"
   ],
   "id": "cdbf35d430329a91",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#now with standarization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Separate features and labels\n",
    "features = XY_train.drop(columns=['OUTCOME'])\n",
    "labels = XY_train['OUTCOME']\n",
    "\n",
    "# Normalize the features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "normalized_features = scaler.fit_transform(features)\n",
    "\n",
    "# Set a random seed for reproducibility\n",
    "random_seed = 42\n",
    "\n",
    "# Initialize and fit the K-means model\n",
    "kmeans = KMeans(n_clusters=2, random_state=random_seed)\n",
    "clusters = kmeans.fit_predict(normalized_features)\n",
    "\n"
   ],
   "id": "60b43dd70b4165a9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import silhouette_score, adjusted_rand_score, normalized_mutual_info_score\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Silhouette Score\n",
    "silhouette_before = silhouette_score(normalized_features, clusters)\n",
    "print(f\"Silhouette Score (Before PCA): {silhouette_before:.2f}\")\n",
    "\n",
    "from sklearn.metrics import davies_bouldin_score\n",
    "#Davies-Bouldin Index:\n",
    "db_index = davies_bouldin_score(normalized_features, clusters)\n",
    "print(f\"Davies-Bouldin Index: {db_index:.2f}\")\n",
    "\n",
    "# Normalized Mutual Information (NMI)\n",
    "nmi_before = normalized_mutual_info_score(labels, clusters)\n",
    "print(f\"Normalized Mutual Information (Before PCA): {nmi_before:.2f}\")\n"
   ],
   "id": "5639634959933d04",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#now with PCA\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "\n",
    "principal_components = pca.fit_transform(normalized_features)\n",
    "\n",
    "# Print explained variance ratio for each component\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "print(\"Explained Variance Ratio:\", explained_variance_ratio)\n",
    "#sum\n",
    "print(\"Explained Variance Ratio sum:\",pca.explained_variance_ratio_.sum())\n",
    "\n",
    "\n",
    "pca = PCA.fit(normalized_features)"
   ],
   "id": "dec923028048acc2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a DataFrame for the principal components\n",
    "pca_df = pd.DataFrame(data=principal_components, columns=['PC1', 'PC2'])\n",
    "\n",
    "# Add the labels back for coloring the points\n",
    "pca_df['OUTCOME'] = labels\n",
    "\n",
    "# Plot the principal components\n",
    "plt.figure(figsize=(8, 6))\n",
    "for label in pca_df['OUTCOME'].unique():\n",
    "    plt.scatter(\n",
    "        pca_df.loc[pca_df['OUTCOME'] == label, 'PC1'],\n",
    "        pca_df.loc[pca_df['OUTCOME'] == label, 'PC2'],\n",
    "        label=f'Class {label}',\n",
    "        alpha=0.7\n",
    "    )\n",
    "\n",
    "plt.title(\"PCA Visualization\")\n",
    "plt.xlabel(\"Principal Component 1\")\n",
    "plt.ylabel(\"Principal Component 2\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ],
   "id": "8fb561b05277380a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "kmeans_pca = KMeans(n_clusters=2, random_state=random_seed)\n",
    "clusters_pca = kmeans_pca.fit_predict(principal_components)"
   ],
   "id": "f4354d40c1254c4a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Silhouette Score\n",
    "silhouette_after = silhouette_score(principal_components, clusters_pca)\n",
    "print(f\"Silhouette Score (After PCA): {silhouette_after:.2f}\")\n",
    "\n",
    "#Davies-Bouldin Index:\n",
    "db_index = davies_bouldin_score(principal_components, clusters_pca)\n",
    "print(f\"Davies-Bouldin Index: {db_index:.2f}\")\n",
    "\n",
    "# Normalized Mutual Information (NMI)\n",
    "nmi_after = normalized_mutual_info_score(labels, clusters_pca)\n",
    "print(f\"Normalized Mutual Information (After PCA): {nmi_after:.2f}\")"
   ],
   "id": "199a500e676206a4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Visualize the clusters in PCA space\n",
    "plt.figure(figsize=(8, 6))\n",
    "for cluster in np.unique(clusters_pca):\n",
    "    subset = pca_df[clusters_pca == cluster]\n",
    "    plt.scatter(subset['PC1'], subset['PC2'], label=f'Cluster {cluster}', alpha=0.7)\n",
    "\n",
    "plt.title(\"K-means Clusters in PCA Space\")\n",
    "plt.xlabel(\"Principal Component 1\")\n",
    "plt.ylabel(\"Principal Component 2\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "id": "9f3a85392bb34ff5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "#------------------------------------2---------------------SVM\n",
   "id": "a8f813d144f055cb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    ")\n",
    "\n",
    "# Step 1: Load and Preprocess the Dataset\n",
    "# Assuming `XY_train` is the DataFrame with features and the 'OUTCOME' column as the target\n",
    "\n",
    "# Separate features and labels\n",
    "X = XY_train.drop(columns=['OUTCOME'])\n",
    "y = XY_train['OUTCOME']\n",
    "\n",
    "# Split the dataset into training and testing sets (80-20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ],
   "id": "d691ed67802dd53d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Step 2: Train an SVM Model (with class balancing)\n",
    "svm_model = SVC(class_weight='balanced', random_state=42)  # Class_weight addresses class imbalance\n",
    "svm_model.fit(X_train, y_train)"
   ],
   "id": "7d78d6a49f6ce73b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Step 3: Evaluate the Model\n",
    "y_pred = svm_model.predict(X_test)\n",
    "print(\"\\n=== Model Performance ===\")\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.2f}\")\n",
    "print(f\"F1-Score: {f1_score(y_test, y_pred):.2f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred):.2f}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred):.2f}\")"
   ],
   "id": "485fe8d94a263839",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Step 4: Hyperparameter Tuning with GridSearchCV\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'C': [0.1, 1,2, 3, 10],\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'gamma': ['scale', 'auto'],\n",
    "    'class_weight': ['balanced']\n",
    "}\n",
    "\n",
    "# Perform Grid Search with cross-validation\n",
    "grid_search = GridSearchCV(SVC(random_state=42), param_grid, cv=5, scoring='accuracy', verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Display the best parameters and their performance\n",
    "print(\"\\n=== Best Parameters Found ===\")\n",
    "print(grid_search.best_params_)\n"
   ],
   "id": "a4b80276e605a0e3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Save the best model\n",
    "import joblib\n",
    "best_model = grid_search.best_estimator_\n",
    "joblib.dump(best_model, 'best_model.pkl')\n",
    "print(\"Model saved as 'best_model.pkl'.\")"
   ],
   "id": "8ba5317c9e7ef7e3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Step 5: Evaluate the Best Model on Test Set\n",
    "best_model = grid_search.best_estimator_\n",
    "y_best_pred = best_model.predict(X_test)\n",
    "\n",
    "print(\"\\n=== Best Model Performance ===\")\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_best_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_best_pred))\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_best_pred):.2f}\")\n",
    "print(f\"F1-Score: {f1_score(y_test, y_best_pred):.2f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_best_pred):.2f}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_best_pred):.2f}\")"
   ],
   "id": "101c1ba1f8e13754",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create a DataFrame from the grid search results\n",
    "results_df = pd.DataFrame(grid_search.cv_results_)"
   ],
   "id": "719af6253180061c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Extract the parameter combinations and corresponding models from the grid search\n",
    "all_params = grid_search.cv_results_['params']\n",
    "all_models = grid_search.cv_results_\n",
    "\n",
    "# Create a DataFrame to store the results\n",
    "results = []\n",
    "\n",
    "for params in all_params:\n",
    "    # Train an SVM model with the current parameter combination\n",
    "    model = SVC(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = model.score(X_test, y_test)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    confusion = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    # Save results\n",
    "    results.append({\n",
    "        \"params\": params,\n",
    "        \"accuracy\": accuracy,\n",
    "        \"f1_score\": report[\"weighted avg\"][\"f1-score\"],\n",
    "        \"precision\": report[\"weighted avg\"][\"precision\"],\n",
    "        \"recall\": report[\"weighted avg\"][\"recall\"],\n",
    "        \"confusion_matrix\": confusion\n",
    "    })\n",
    "\n",
    "# Convert the results to a DataFrame for better analysis\n",
    "import pandas as pd\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Sort by accuracy or any other metric\n",
    "sorted_results = results_df.sort_values(by=\"accuracy\", ascending=False)\n",
    "\n",
    "# Display the top models\n",
    "print(sorted_results.head())\n"
   ],
   "id": "a9fa9a976ebc2688",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming you have the grid_search results\n",
    "# Replace `grid_search.cv_results_` with your actual GridSearchCV results\n",
    "mean_test_scores = grid_search.cv_results_['mean_test_score']\n",
    "param_C = [params['C'] for params in grid_search.cv_results_['params']]\n",
    "param_kernel = [params['kernel'] for params in grid_search.cv_results_['params']]\n",
    "\n",
    "# Create a DataFrame for visualization\n",
    "results_df = pd.DataFrame({\n",
    "    'C': param_C,\n",
    "    'Kernel': param_kernel,\n",
    "    'Mean Test Score': mean_test_scores\n",
    "})\n",
    "\n",
    "# Aggregate the data to handle duplicate entries\n",
    "aggregated_results = results_df.groupby(['C', 'Kernel'])['Mean Test Score'].mean().reset_index()\n",
    "\n",
    "# Pivot for heatmap\n",
    "pivot_table = aggregated_results.pivot(index='C', columns='Kernel', values='Mean Test Score')\n",
    "\n",
    "# Heatmap\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(pivot_table, annot=True, cmap='coolwarm', fmt='.3f', linewidths=0.5)\n",
    "plt.title('Grid Search Results: Mean Test Scores for C and Kernel', fontsize=14)\n",
    "plt.xlabel('Kernel', fontsize=12)\n",
    "plt.ylabel('C', fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "# Line Plot: Performance trends across C values for each kernel\n",
    "plt.figure(figsize=(10, 6))\n",
    "for kernel in aggregated_results['Kernel'].unique():\n",
    "    kernel_data = aggregated_results[aggregated_results['Kernel'] == kernel]\n",
    "    plt.plot(kernel_data['C'], kernel_data['Mean Test Score'], label=f'Kernel: {kernel}', marker='o')\n",
    "\n",
    "plt.title('Mean Test Scores vs. C for Different Kernels', fontsize=14)\n",
    "plt.xlabel('C', fontsize=12)\n",
    "plt.ylabel('Mean Test Score', fontsize=12)\n",
    "plt.legend(title='Kernel')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Bar Chart: Highlighting top-performing combinations\n",
    "top_results = aggregated_results.sort_values(by='Mean Test Score', ascending=False).head(5)\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=top_results, x='C', y='Mean Test Score', hue='Kernel', dodge=True, palette='viridis')\n",
    "plt.title('Top 5 Hyperparameter Combinations by Mean Test Score', fontsize=14)\n",
    "plt.xlabel('C', fontsize=12)\n",
    "plt.ylabel('Mean Test Score', fontsize=12)\n",
    "plt.legend(title='Kernel')\n",
    "plt.show()\n"
   ],
   "id": "18eff8a6da981472",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Evaluate the best model on the test set\n",
    "best_model = grid_search.best_estimator_\n",
    "test_accuracy = best_model.score(X_test, y_test)\n",
    "train_accuracy =  best_model.score(X_train, y_train)\n",
    "\n",
    "print(f\"Accuracy on the training set: {train_accuracy:.2f}\")\n",
    "print(f\"Accuracy on the test set: {test_accuracy:.2f}\")\n"
   ],
   "id": "425a750451019e90",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load the model from the file\n",
    "with open('best_decision_tree_model.pkl', 'rb') as file:\n",
    "    loaded_model = pickle.load(file)\n",
    "\n",
    "print(\"Model loaded successfully!\")\n"
   ],
   "id": "42d4cd87316186c0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "# Generate predictions for the test set\n",
    "y_test_pred = loaded_model.predict(X_test)\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "conf_matrix = confusion_matrix(Y_test, y_test_pred)\n",
    "\n",
    "# Display the confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=['Class 0', 'Class 1'])\n",
    "disp.plot(cmap='Blues', values_format='d')\n",
    "plt.title('Confusion Matrix for Loaded Model')\n",
    "plt.show()\n"
   ],
   "id": "403abc0b967446e6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv(\"X_test.csv\", encoding='iso-8859-1')\n",
    "\n",
    "# ======== MISSION 0 ========\n",
    "# split input dataset to training dataset & testing dataset\n",
    "\n",
    "# remove irrelevant columns\n",
    "df_imputed = df.drop(columns=['ID', 'POSTAL_CODE'])\n",
    "\n",
    "# convert values to numerical\n",
    "df_imputed['GENDER'] = df_imputed['GENDER'].map({'male': 0, 'female': 1})\n",
    "df_imputed['EDUCATION'] = df_imputed['EDUCATION'].map({'none': 0, 'high school': 1, 'university': 2})\n",
    "df_imputed['VEHICLE_TYPE'] = df_imputed['VEHICLE_TYPE'].map({'sedan': 0, 'sports car': 1})\n",
    "df_imputed['VEHICLE_YEAR'] = df_imputed['VEHICLE_YEAR'].map({'before 2015': 0, 'after 2015': 1})\n",
    "df_imputed['INCOME'] = df_imputed['INCOME'].map({'poverty': 0, 'working class': 1, 'middle class': 2, 'upper class': 3})\n",
    "\n",
    "df_imputed['AGE'] = pd.cut(df_imputed['AGE'], bins=[0, 20, 30, 50, 70, 100], labels=[0, 1, 2, 3, 4])\n",
    "df_imputed['DRIVING_EXPERIENCE'] = pd.cut(df_imputed['DRIVING_EXPERIENCE'], bins=[0, 1, 3, 10, 20, 100],\n",
    "                                          labels=[0, 1, 2, 3, 4])\n",
    "\n",
    "# remove rows with missing values\n",
    "df_imputed = df_imputed.dropna()"
   ],
   "id": "938b12f7b669afcb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pickle\n",
    "\n",
    "# Load the training data\n",
    "XY_train = pd.read_csv(\"XY_train.csv\", encoding='iso-8859-1')\n",
    "\n",
    "# Drop irrelevant columns\n",
    "XY_train = XY_train.drop(columns=['ID', 'POSTAL_CODE'])\n",
    "\n",
    "# Convert categorical variables to numerical\n",
    "XY_train['GENDER'] = XY_train['GENDER'].map({'male': 0, 'female': 1})\n",
    "XY_train['EDUCATION'] = XY_train['EDUCATION'].map({'none': 0, 'high school': 1, 'university': 2})\n",
    "XY_train['VEHICLE_TYPE'] = XY_train['VEHICLE_TYPE'].map({'sedan': 0, 'sports car': 1})\n",
    "XY_train['VEHICLE_YEAR'] = XY_train['VEHICLE_YEAR'].map({'before 2015': 0, 'after 2015': 1})\n",
    "XY_train['INCOME'] = XY_train['INCOME'].map({'poverty': 0, 'working class': 1, 'middle class': 2, 'upper class': 3})\n",
    "\n",
    "XY_train['AGE'] = pd.cut(XY_train['AGE'], bins=[0, 20, 30, 50, 70, 100], labels=[0, 1, 2, 3, 4])\n",
    "XY_train['DRIVING_EXPERIENCE'] = pd.cut(XY_train['DRIVING_EXPERIENCE'],\n",
    "                                        bins=[0, 1, 3, 10, 20, 100], labels=[0, 1, 2, 3, 4])\n",
    "\n",
    "# Handle missing values using KNNImputer\n",
    "numeric_columns = [\"ANNUAL_MILEAGE\", \"CREDIT_SCORE\"]\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Scale the numeric columns\n",
    "scaled_data = scaler.fit_transform(XY_train[numeric_columns])\n",
    "\n",
    "# Apply KNNImputer to the scaled data\n",
    "knn_imputer = KNNImputer(n_neighbors=6)\n",
    "imputed_data = knn_imputer.fit_transform(scaled_data)\n",
    "\n",
    "# Replace the original columns with the imputed ones (inverse scale)\n",
    "XY_train[numeric_columns] = scaler.inverse_transform(imputed_data)\n",
    "\n",
    "# Separate features and target variable\n",
    "X_train = XY_train.drop(columns=['OUTCOME'])\n",
    "Y_train = XY_train['OUTCOME']\n",
    "\n",
    "# Load the test data\n",
    "X_test = pd.read_csv(\"X_test.csv\", encoding='iso-8859-1')\n",
    "\n",
    "# Preprocess the test data (same steps as training)\n",
    "X_test = X_test.drop(columns=['ID', 'POSTAL_CODE'])\n",
    "X_test['GENDER'] = X_test['GENDER'].map({'male': 0, 'female': 1})\n",
    "X_test['EDUCATION'] = X_test['EDUCATION'].map({'none': 0, 'high school': 1, 'university': 2})\n",
    "X_test['VEHICLE_TYPE'] = X_test['VEHICLE_TYPE'].map({'sedan': 0, 'sports car': 1})\n",
    "X_test['VEHICLE_YEAR'] = X_test['VEHICLE_YEAR'].map({'before 2015': 0, 'after 2015': 1})\n",
    "X_test['INCOME'] = X_test['INCOME'].map({'poverty': 0, 'working class': 1, 'middle class': 2, 'upper class': 3})\n",
    "\n",
    "X_test['AGE'] = pd.cut(X_test['AGE'], bins=[0, 20, 30, 50, 70, 100], labels=[0, 1, 2, 3, 4])\n",
    "X_test['DRIVING_EXPERIENCE'] = pd.cut(X_test['DRIVING_EXPERIENCE'],\n",
    "                                      bins=[0, 1, 3, 10, 20, 100], labels=[0, 1, 2, 3, 4])\n",
    "\n",
    "# Scale the numeric columns in test data and impute missing values\n",
    "X_test[numeric_columns] = scaler.transform(X_test[numeric_columns])\n",
    "X_test[numeric_columns] = scaler.inverse_transform(knn_imputer.transform(X_test[numeric_columns]))\n",
    "\n",
    "# Load the saved model\n",
    "with open(\"best_decision_tree_model.pkl\", \"rb\") as file:\n",
    "    loaded_model = pickle.load(file)\n",
    "\n",
    "# Make predictions on the preprocessed test data\n",
    "y_test_pred = loaded_model.predict(X_test)\n",
    "\n",
    "# Create the output DataFrame in the required format\n",
    "y_test_output = pd.DataFrame({'target': y_test_pred})\n",
    "\n",
    "# Save the predictions to an Excel file\n",
    "y_test_output.to_excel(\"y_test_predictions.xlsx\", index=False)\n",
    "\n",
    "print(\"Predictions saved to 'y_test_predictions.xlsx'\")\n"
   ],
   "id": "b9e838cd82d5ceda",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "3783c121c6c344e0",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
